{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb08/ZCkN4AgRuab0IMFwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhild1111/DSBDA/blob/main/C1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "web scraping means pull out the nesssory data or scap the imporatant data in websiite larg numberr of data is present and we will pull out the imporatant dtaa"
      ],
      "metadata": {
        "id": "KIDXoElSXqgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SnIuytpXps3"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bs4 (short for BeautifulSoup4) â€“\n",
        "Itâ€™s used for parsing and extracting data from HTML or XML documents.\n",
        "Basically, requests helps you fetch the page, and bs4 helps you analyze and extract the information from it."
      ],
      "metadata": {
        "id": "pfsITJEMaJju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "requst libary we are using to send the http requst to the perticlur URL using get post this kim=nd of website we can either we can retrive data feom the website or send data tot he server but here we are just retrive the data from the server"
      ],
      "metadata": {
        "id": "EYPHesorYQNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'\n",
        "}\n",
        "\n",
        "request1 = requests.get('https://www.amazon.in/Dyson-Supersonic-dryer-Nickel-copper/dp/B0C3J21K1G?th=1', headers=headers)\n",
        "request1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9cV66CsaQv0",
        "outputId": "a091467c-3be8-4ab9-f258-52291d72c123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " request1 now contains the HTTP response.\n",
        "But Flipkart usually detects bots and may block or redirect the page unless you act like a real browser."
      ],
      "metadata": {
        "id": "DXvc3CTdcIDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "request1.content"
      ],
      "metadata": {
        "id": "S5Z2Oc3DajIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# soup = BeautifulSoup(request1.content, 'html.parser')\n",
        "# print(soup.prettify())  # prints nicely formatted HTML\n",
        "# soup #print the content as it is not formated"
      ],
      "metadata": {
        "id": "TiE9sdZOcHLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " .text\n",
        "\n",
        "Gives decoded and readable HTML.\n",
        "\n",
        "Type: str (string)\n",
        "\n",
        "Good for simple English websites.\n",
        "\n",
        "ðŸ”µ .content\n",
        "\n",
        "Gives raw and exact HTML (in bytes).\n",
        "\n",
        "Type: bytes\n",
        "\n",
        "Safer for complex or non-English websites."
      ],
      "metadata": {
        "id": "Tu7a4mwDenQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(request1.text, 'html.parser')\n",
        "soup"
      ],
      "metadata": {
        "id": "FoFhwLx0fD02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part\tMeaning\n",
        "request1.content\tThis is the raw HTML you got from the website (Flipkart, Quotes, etc.)\n",
        "BeautifulSoup(...)\tBeautifulSoup takes that messy HTML and parses (reads) it in a clean, structured way.\n",
        "'html.parser'\tThis tells BeautifulSoup how to parse â€” here, we are saying: \"parse it as normal HTML\". (There are other parsers too, like 'lxml', but 'html.parser' is built into Python.)\n",
        "soup\tNow you have a beautifully structured object (soup) where you can easily find elements like titles, prices, buttons, etc."
      ],
      "metadata": {
        "id": "iFXdUvAxffwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getComment(soup):\n",
        "    Comment_list = []\n",
        "    for item in soup.find_all(\"li\", class_=\"review\"):\n",
        "        title = item.find(\"a\", class_=\"review-title-content\")\n",
        "        body = item.find(\"span\", class_=\"review-text\")\n",
        "\n",
        "        # Check if the review elements exist\n",
        "        review = {\n",
        "            \"title\": title.get_text().split(\"\\n\", 1)[1]  if title else \"No title\",\n",
        "            \"body\": body.get_text() if body else \"No review text\"\n",
        "        }\n",
        "        Comment_list.append(review)\n",
        "    return Comment_list\n"
      ],
      "metadata": {
        "id": "l2jG4DlhfzGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Comment_res = getComment(soup)\n",
        "print(\"\\nComments:\", Comment_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlLMge51fzeM",
        "outputId": "97a92fff-f7c8-4153-fa32-d05538043205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comments: [{'title': 'Its makes less noise and distributed heat evenly\\n', 'body': '\\n\\n\\nStylish, powerful, easy to use, less noise when compare to other brands, perfect for boutique use.\\nRead more'}, {'title': 'Worst Product\\n', 'body': '\\nWaste of money, its not drying properly. No comfort.  I dont know why it cost too much. Very  Very bad\\nRead more'}, {'title': 'Excellent product.\\n', 'body': \"\\nWhat an absolute beauty this product is..works like a Terminator, product of my dreams as I am poor and I can't afford it. Highly recommended if you can afford it. Would have sold my half kidney if was a girl and had long hairs.\\nRead more\"}, {'title': 'No title', 'body': '\\n\\n\\nDyson makes super products and this hair dryer does not disappoint . Itâ€™s fantastic. I have very curly hair and it doesnâ€™t give me frizzy hair . Worth every cent\\nRead more'}, {'title': 'No title', 'body': \"\\ndon't buy dyson online, they won't warranty and either will dyson.\\nRead more\"}, {'title': 'No title', 'body': '\\nDyson hair dryer, dries hair fast and with out frizzing your hair\\nRead more'}, {'title': 'No title', 'body': '\\nI got this for my wife and she tells me everyday how much she loves it , she also said she wish she would of got one years ago .\\nRead more'}, {'title': 'No title', 'body': '\\nI like  time saving  drying my hair  and keeps  my hair soft and healthy\\nRead more'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "soup: This is the BeautifulSoup object that holds the parsed HTML of the page.\n",
        "\n",
        "find_all(): This is a BeautifulSoup method that searches for all occurrences of a particular tag and class within the parsed HTML. It returns a list of all matching elements.\n",
        "\n",
        "find_all(tag, class_='class-name'):\n",
        "\n",
        "tag: The HTML tag you are searching for (like div, span, a, etc.).\n",
        "\n",
        "class_: The CSS class attribute of the HTML element you're targeting."
      ],
      "metadata": {
        "id": "ebUOR2keg93N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getRatings(soup):\n",
        "    ratings_list = []\n",
        "    for item in soup.find_all(\"li\", class_=\"review\"):  # Loop through each review\n",
        "        # Extract customer name\n",
        "        customer_name = item.find(\"span\", class_=\"a-profile-name\")\n",
        "        name = customer_name.get_text().strip() if customer_name else \"Anonymous\"\n",
        "\n",
        "        # Extract rating\n",
        "        rating = item.find(\"i\", class_=\"review-rating\")\n",
        "        rating_value = rating.find(\"span\", class_=\"a-icon-alt\").get_text().strip() if rating else \"No rating\"\n",
        "\n",
        "        # Add the rating details to the list\n",
        "        ratings_list.append({\n",
        "            \"customer_name\": name,\n",
        "            \"rating\": rating_value\n",
        "        })\n",
        "\n",
        "    return ratings_list"
      ],
      "metadata": {
        "id": "eGY0gSzvfzhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_res = getRatings(soup)\n",
        "print(\"\\nRatings:\", rating_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjV7QUt2fzj-",
        "outputId": "02c87b99-3732-4c43-f424-4cb998a07fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ratings: [{'customer_name': 'Amazon Customer', 'rating': '4.0 out of 5 stars'}, {'customer_name': 'Akash Srivastava', 'rating': '1.0 out of 5 stars'}, {'customer_name': 'Shubham', 'rating': '5.0 out of 5 stars'}, {'customer_name': 'Susan', 'rating': '5.0 out of 5 stars'}, {'customer_name': 'greg', 'rating': '1.0 out of 5 stars'}, {'customer_name': 'Birdie', 'rating': '5.0 out of 5 stars'}, {'customer_name': 'Beast from the east', 'rating': '5.0 out of 5 stars'}, {'customer_name': 'Janet Hong', 'rating': '4.0 out of 5 stars'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getavgReviews(soup):\n",
        "    avgreview_list = []\n",
        "    for item in soup.find_all(\"span\", class_=\"a-size-medium a-color-base\"):\n",
        "        avgreview_list.append(item.get_text())\n",
        "    return avgreview_list"
      ],
      "metadata": {
        "id": "ZcWo6KnKfzmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avgreview_res = getavgReviews(soup)\n",
        "print(\"\\nAvgReviews:\", avgreview_res[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzfqXNx_fzpr",
        "outputId": "92d31ca3-3704-4e48-abd6-ca15fae61147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AvgReviews: 4.3 out of 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prices(soup):\n",
        "    prices = []\n",
        "\n",
        "    # Find all the price elements\n",
        "    price_elements = soup.find_all(\"span\", class_=\"a-price-whole\")\n",
        "\n",
        "    # Loop through the first 10 prices (or fewer if less than 10 available)\n",
        "    for i in range(min(10, len(price_elements))):\n",
        "        price = price_elements[i].get_text().strip().replace(\",\", \"\")  # Clean the price\n",
        "        prices.append(price)\n",
        "\n",
        "    return prices\n"
      ],
      "metadata": {
        "id": "O6qNzVlufztL"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iw2zRt_X6cMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_prices = get_prices(soup)\n",
        "\n",
        "# Print all the prices\n",
        "for price in product_prices:\n",
        "    print(f\"Price: {price}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0XySnrn5zIM",
        "outputId": "fbd0132b-b192-4a46-8880-3b695b0b8dd4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price: 5999.\n",
            "Price: 10710.\n",
            "Price: 3999.\n",
            "Price: 29900.\n",
            "Price: 1289.\n",
            "Price: 1089.\n",
            "Price: 996.\n",
            "Price: 1019.\n",
            "Price: 3999.\n",
            "Price: 3999.\n"
          ]
        }
      ]
    }
  ]
}